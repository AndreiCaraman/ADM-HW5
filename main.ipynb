{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e40a805-b4c8-4c5f-90e5-f34c40984800",
   "metadata": {},
   "source": [
    "# Exploring StackOverflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633c5809-17a8-4c32-b86c-f4d1219bd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13428b8f-87cc-4e27-860b-3e3d044ed6dc",
   "metadata": {},
   "source": [
    "## Populating the Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f820739-473e-4e8a-913a-02c6f5c3f758",
   "metadata": {},
   "source": [
    "Each graph is build independantly from the provided `.txt` files of temporal network of interactions. \\\n",
    "Users are represented as nodes and answers\\comments as edges.\n",
    "\n",
    "The design choices of the following method are:\n",
    "- Using directed graphs. \n",
    "- *Simple* graphs, there are no loops in the graphs. Users who answer to themselves are discarded cases.\n",
    "- Only one attributes is assigned to the edges: weight. The weights are:\n",
    "    - `1` for answers to questions\n",
    "    - `.75` for comments on questions\n",
    "    - `.5` for comments to answers\n",
    "- Time resolution is one day.\n",
    "- The graphs are build given a time input to avoid such attribute for the sake of simplicity and robustess.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcb35e9-e745-4a97-a9ca-c989189dcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_time_int_to_dates(time_interval):\n",
    "    # Convert the time interval in start and end dates \n",
    "    time_interval = tuple(map(datetime.fromisoformat, time_interval)) # converting time interval into datetime format\n",
    "    time_interval = tuple(map(datetime.timestamp, time_interval)) # converting time interval into POSIX timestamp \n",
    "    start_d = int(time_interval[0]) #converting to string to compare with the txt\n",
    "    end_d = int(time_interval[1])\n",
    "    return start_d, end_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c5a139-7b19-4103-bde8-8bff65ec591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(time_interval, file = 3):\n",
    "    \n",
    "    # Initialize the graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Create mapping of files and mapping of weights\n",
    "    map_files = {1: \"sx-stackoverflow-a2q.txt\", 2:\"sx-stackoverflow-c2q.txt\", 3:\"sx-stackoverflow-c2a.txt\"}\n",
    "    map_weights = {1: 1.0, 2: .75, 3: .5}\n",
    "    \n",
    "    # Get the start and end dates \n",
    "    start, end = from_time_int_to_dates(time_interval)\n",
    "    \n",
    "    # Select the file chosen, open it and read the lines\n",
    "    with open(map_files[file], \"r\", encoding=\"UTF-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            \n",
    "            # Parse the line\n",
    "            elems = line.split(' ')\n",
    "            date = int(elems[2])\n",
    "            if date <= end:\n",
    "                # Add to the graph if it is in the time interval\n",
    "                if date >= start:\n",
    "                    # If the edge already exists --> increment the weight, else simply add the new edge\n",
    "                    if (elems[0], elems[1]) in G.edges():\n",
    "                        G[elems[0]][elems[1]]['weight'] += float(map_weights[file])\n",
    "                    else:\n",
    "                        G.add_edge(elems[0], elems[1], weight = float(map_weights[file]))\n",
    "            else:\n",
    "                break\n",
    "                    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e418e61-18ae-4ca3-b099-e2162127e3a2",
   "metadata": {},
   "source": [
    "### Merging the graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8c473-b071-4a5a-8f01-d0597e1ff29e",
   "metadata": {},
   "source": [
    "This function will merge two graphs that were obtained by the function **get_graph()** with the same time interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea53ebc-8ba8-4beb-ba6c-fe2985e52564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_graph(graph_1, graph_2):\n",
    "    \n",
    "    # Iterate over the edges from the second graph\n",
    "    for edge_2 in graph_2.edges(data = True):\n",
    "        # If the edge of graph 2 is also in graph 1, only sum weights\n",
    "        if (edge_2[0],edge_2[1]) in graph_1.edges():\n",
    "            graph_1[edge_2[0]][edge_2[1]]['weight'] += float(edge_2[2]['weight'])\n",
    "        # Else add the edge of graph 2 also in graph 1\n",
    "        else:\n",
    "            graph_1.add_edge(edge_2[0], edge_2[1], weight = float(edge_2[2]['weight']))\n",
    "            \n",
    "    return graph_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18fb79c-5141-4621-ab0f-b6fd34495f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_merged_graph(TimeInterval):\n",
    "    # generating graph\n",
    "    graph1 = get_graph(time_interval=TimeInterval, file=1)\n",
    "    graph2 = get_graph(time_interval=TimeInterval, file=2)\n",
    "    graph3 = get_graph(time_interval=TimeInterval, file=3)\n",
    "    merged = merged_graph(graph1, graph2)\n",
    "    merged = merged_graph(merged, graph3)\n",
    "    d_merge = nx.to_dict_of_dicts(merged)\n",
    "    \n",
    "    return merged, d_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "876acf3e-41e1-4321-8ad2-b95b2e31a3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged, d_merge = build_merged_graph((\"2008-11-01\",\"2008-11-02\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3198d9-4c5d-49db-a906-8dbff551a931",
   "metadata": {},
   "source": [
    "### Functionality 1 - Get the overall features of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52219954-599c-451e-b611-805763fb621b",
   "metadata": {},
   "source": [
    "Graph density/sprcity is computed as defined in *\"Introduction to Algorithms\" by Cormern, Leiserson, Rivest, and Stein*: \\\n",
    "A graph $G = (E, V)$, with $E$ denoting the edges and $V$ denoting the vertices,  is sparse if $|E| << |V|^2$ and dense if $|E|$ is close to $|V|$. \\\n",
    "And so if $|E|$ differs an order of magnitude from $|V|$ the graph is considered sparse, otherwise it is dense.\n",
    "The density degree expression is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{|V|}{|E|(|E| - 1)} \\approx \\frac{|V|}{|E|^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c212be-1f90-4d00-b0cd-a1f1f2bd3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: a boolean True/False\n",
    "\n",
    "def directed(dict_graph):\n",
    "    direct = False\n",
    "    # Iterating through the dictionary items\n",
    "    for node, neighbours in dict_graph.items():\n",
    "        # For each list of adjacency of node\n",
    "        for neighbour in list(neighbours.keys()):\n",
    "            # If the node is not present in the adj list of his neighbours --> break\n",
    "            if node not in list(dict_graph[neighbour].keys()):\n",
    "                direct = True\n",
    "                break\n",
    "    return direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0d17b4-3d64-47ba-aecb-85220bc15ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: number of nodes in the graph\n",
    "\n",
    "def n_users(dict_graph):\n",
    "    # Return number of keys\n",
    "    return len(dict_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2821b314-94dc-4cf2-8e15-8eee0e212945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: number of edges in the graph\n",
    "\n",
    "# For this implementation we considered the \"out-degree\" = number of edges coming out from the node \n",
    "def n_interactions(dict_graph):\n",
    "    # Sum the length of lists of edges\n",
    "    n_int = 0\n",
    "    for neighbour in dict_graph.values():\n",
    "        n_int += len(list(neighbour.keys()))\n",
    "    return n_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de77e33-28fe-4fdc-a516-bb9c27d1a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: average number of links for nodes\n",
    "\n",
    "def average_n_links(dict_graph):\n",
    "    return n_interactions(dict_graph) / n_users(dict_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e876a7e4-104c-4f63-b848-11d37ea7fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_OverallFeatures(dict_graph):\n",
    "    \"\"\"\n",
    "    Input: One of the 3 graphs in dictionary format\n",
    "\n",
    "    Output:\n",
    "      Whether the graph is directed or not\n",
    "      Number of users\n",
    "      Number of answers/comments\n",
    "      Average number of links per user\n",
    "      Density degree of the graph\n",
    "      Whether the graph is sparse or dense\n",
    "    \"\"\"\n",
    "    \n",
    "    # quering if the graph is directed\n",
    "    Directed = directed(dict_graph)\n",
    "    \n",
    "    # using a variable to print the output\n",
    "    if Directed: \n",
    "        IsDirectedPrint = 'directed'\n",
    "    else:\n",
    "        IsDirectedPrint = 'undirected'\n",
    "        \n",
    "    # computing the number of users\n",
    "    NofUsers = n_users(dict_graph) \n",
    "    \n",
    "    # computing the number of interactions\n",
    "    NofInteractions = n_interactions(dict_graph)\n",
    "    \n",
    "    # computing the avarege number of links per user\n",
    "    AvgUserLinks = average_n_links(dict_graph)\n",
    "    \n",
    "    # computing density degree\n",
    "    DensityDegree = NofInteractions / NofUsers**2\n",
    "    \n",
    "    # evaluating sparsity/density\n",
    "    if NofUsers / NofInteractions**2 < 10:\n",
    "        SparseDense = 'sparse'\n",
    "    else:\n",
    "        SparseDense = 'dense'\n",
    "        \n",
    "    # print the results\n",
    "    print(f\"The input graph is -> {IsDirectedPrint}\")\n",
    "    print(f\"Number of users -> {NofUsers}\")\n",
    "    print(f\"Number of answers/comments -> {NofInteractions}\")\n",
    "    print(f\"Average number of links per user -> {AvgUserLinks:.2}\")\n",
    "    print(f\"Density degree -> {DensityDegree: .2}\")\n",
    "    print(f\"The graph is -> {SparseDense}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fd84ba2-5d0e-4890-a02a-5d8fa389a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input graph is -> directed\n",
      "Number of users -> 1043\n",
      "Number of answers/comments -> 1538\n",
      "Average number of links per user -> 1.5\n",
      "Density degree ->  0.0014\n",
      "The graph is -> sparse\n"
     ]
    }
   ],
   "source": [
    "F1_OverallFeatures(d_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c082fc5-e279-4ed4-aa69-ef9435efe06e",
   "metadata": {},
   "source": [
    "### Functionality 2 - Find the best users!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114fc890-f318-422f-9cd0-7d649dd46a6e",
   "metadata": {},
   "source": [
    "#### Degree centrality\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the normalized degree centrality of node $v$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d_v}{|V|-1} \\approx \\frac{d_v}{|V|}\n",
    "\\end{equation}\n",
    "\n",
    "with $d_v$ the degree of the node $v$, i.e. the number of edges incident to the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32c83582-ab3e-47e1-864f-124be4f1bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the degree as \"out-degree\"\n",
    "def degree(dict_graph, node):\n",
    "    return len(list(dict_graph[node].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffc2ca18-61b9-4fe9-afe5-fbaa9b18aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the degree as \"in-degree\"\n",
    "def in_degree(dict_graph, node):\n",
    "    out = 0\n",
    "    for u in list(dict_graph.keys()):\n",
    "        if u != node and (node in list(dict_graph[u].keys())):\n",
    "            out += 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83655f9a-1eea-4b88-96e6-802b18206f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the definition\n",
    "def degree_centrality(dict_graph, node):\n",
    "    out = degree(dict_graph, node) / n_interactions(dict_graph)\n",
    "    print(f\"{out:.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b48406a-a9ec-4841-971a-5cd472374042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013\n"
     ]
    }
   ],
   "source": [
    "degree_centrality(d_merge, \"30155\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52b09d0-6513-40ae-9d13-0dddf34cc31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002\n"
     ]
    }
   ],
   "source": [
    "degree_centrality(d_merge, \"4120\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45da09-30c8-4288-b7d4-0744200af52a",
   "metadata": {},
   "source": [
    "#### Closeness centrality\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the normalized closeness centrality of node $v$ is:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{|V|-1}{\\sum_{u \\epsilon V} d(v,u)} \\approx \\frac{|V|}{\\sum_{u \\epsilon V} d(v,u)}\n",
    "\\end{equation}\n",
    "\n",
    "with $d(v,u)$ the distance between nodes $v$ and $u$, that is the length of a shortest path between $v$ and $u$.\\\n",
    "As a design choice $d(v,u)$ is taken as the inverse of the weight of the edge of $(v,u)$, this leads to an inverse relationship between interaction and distances: the more a user posts, the closer he gets to the comunity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "777470dc-f01d-45cf-8f23-a38c6242e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outgoing_edges(dict_graph, node):\n",
    "    return list(dict_graph[node].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16d0278-6ace-4ba3-989d-f2d3b103866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts, the start node\n",
    "# Output: two dictionaries: the first memorize the nodes involved in the shortest paths, the second is the shortest path in distance terms.\n",
    "# Pseudocode from: https://en.wikipedia.org/wiki/Dijkstra's_algorithm#Pseudocode\n",
    "\n",
    "def shortest_path_Dijkstra(dict_graph, node):\n",
    "    \n",
    "    # Initialize two dictionaries to track visited nodes and weights\n",
    "    nodes_dist = dict.fromkeys(dict_graph.keys(), float('inf'))\n",
    "    \n",
    "    # Initialize another dictionary that track the nodes in the shortest path\n",
    "    previous_nodes = dict.fromkeys(dict_graph.keys())\n",
    "    \n",
    "    # Create a list of the unvisited nodes \n",
    "    unvisited = list(dict_graph.keys())\n",
    "    \n",
    "    # First update on the selected node\n",
    "    nodes_dist[node] = 0\n",
    "    \n",
    "    # Start iterating until each node is visited\n",
    "    while(unvisited):\n",
    "        \n",
    "        # Select the current min_node with a for-loop\n",
    "        min_node = None\n",
    "        for n in unvisited:\n",
    "            if min_node == None:\n",
    "                min_node = n\n",
    "            elif nodes_dist[n] < nodes_dist[min_node]:\n",
    "                min_node = n\n",
    "            \n",
    "        # Update distances of the current min_node's neighbors\n",
    "        neighbors = get_outgoing_edges(dict_graph, min_node)\n",
    "        for neighbor in neighbors:\n",
    "            # Calculate the possible update to the shortest path and check if it is < then the actual distance\n",
    "            possible_update = nodes_dist[min_node] + dict_graph[min_node][neighbor]['weight']\n",
    "            if possible_update < nodes_dist[neighbor]:\n",
    "                nodes_dist[neighbor] = possible_update\n",
    "                # We also update the best path to the current node\n",
    "                previous_nodes[neighbor] = min_node\n",
    "        \n",
    "        # Remove the current min_node from the unvisited list\n",
    "        unvisited.remove(min_node)\n",
    "    \n",
    "    return previous_nodes, nodes_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f8853f-b26c-4e29-9c96-739d4fd8c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_shortest_path(previous_nodes, start_node, target_node):\n",
    "    path = []\n",
    "    node = target_node\n",
    "    \n",
    "    while node != start_node:\n",
    "        if node == None:\n",
    "            return []\n",
    "        path.append(node)\n",
    "        node = previous_nodes[node]\n",
    "        \n",
    "    # Add the start node manually\n",
    "    path.append(start_node)\n",
    "    \n",
    "    return list(reversed(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a63c496-a303-4f36-a0fb-dabe51f48598",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_nodes , nodes_distances = shortest_path_Dijkstra(d_merge, '18313')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e403306-33c0-443a-abb7-9f378f5ea1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peso totale con cui vado da '18313' a \"19964\"\n",
    "min_dis_dijk = nodes_distances[\"19964\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faf66554-d72f-4c1c-83a5-4987d27178df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_dis_dijk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa3e46eb-578a-46f6-b214-dbe145d1c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path completo dall'inizio alla fine\n",
    "nodes_shortest_path(prev_nodes,'18313', \"19964\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e433537-64c2-4ca1-b45b-38a157bdea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_closeness_centrality(dict_graph, v):\n",
    "    \n",
    "    # Create a list with all the nodes except the one considered\n",
    "    nodes = list(dict_graph.keys())\n",
    "    nodes.remove(v)\n",
    "    \n",
    "    # Iterate and calculate the denominator adding all the distances calculated with Dijkstra\n",
    "    denom = 0\n",
    "    _, dists = shortest_path_Dijkstra(dict_graph, v)\n",
    "    \n",
    "    for u in nodes:\n",
    "        denom += dists[u]\n",
    "        \n",
    "    # Return the result\n",
    "    return (n_users(dict_graph)) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b0601fd-bf3c-4ec6-819c-b915421bf3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_closeness_centrality(d_merge, \"18313\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fb2bb46-1c44-4d6a-9315-d82a2812a78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_closeness_centrality(d_merge, \"19964\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df06f29-b1a6-496e-8dbb-6d1149e30120",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc2d6ff-a139-4cda-8323-9ec597906d4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "The page rank algorithm will be implemented with Random Surfer Model in which we will use a value $\\alpha$ to adjust all the points in the matrix of edges(a matrix where there are ones if the edge exists and zeros otherwise).\n",
    "\n",
    "The matrix of edges could be full of zeros, so in order to save space in memory, we will not store it. We simply modify a dictionary with as keys the nodes and as values the corrispondant page rank score:\n",
    "\n",
    "The update equation looks like this:\n",
    "\n",
    "\\begin{equation}\n",
    "PageRank(v) = \\frac{\\alpha}{n} + (1-\\alpha) * \\sum_{e_{u,v} \\in E}^{} \\frac{PageRank(u)}{OutDegree(u)}\n",
    "\\end{equation}\n",
    "\n",
    "where $v$ is the target node, $n$ is the number of edges in the graph and $e_{u,v} \\in E$ means that exists an edge between $u$ and $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3d47064-91dd-4f7b-9d98-51b79c1984d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return a list of all parents of a node\n",
    "\n",
    "def get_parents(dict_graph, node):\n",
    "    out = []\n",
    "    for u in list(dict_graph.keys()):\n",
    "        # Check for each node in which children list appear and append it to the final list\n",
    "        if u != node and (node in list(dict_graph[u].keys())):\n",
    "            out.append(u)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07dbab77-b9ce-490b-9b71-db72228243bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return a list of children of a node\n",
    "\n",
    "def get_children(dict_graph, node):\n",
    "    return list(dict_graph[node].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c32991c-83e9-42fe-b4f0-cb4d08965a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will execute the update to the pagerank dictionary\n",
    "\n",
    "def update_pagerank(dict_graph, node, alpha, pagerank):\n",
    "    \n",
    "    # Take the parents of the node\n",
    "    parents = get_parents(dict_graph, node)\n",
    "    \n",
    "    # Calculate the sum term of the formula\n",
    "    pagerank_sum = sum((pagerank[node] / len(get_children(dict_graph, node))) for node in parents)\n",
    "    \n",
    "    # Calculate the random alpha-dependent term\n",
    "    random_walk = alpha / n_users(dict_graph)\n",
    "    \n",
    "    # Update the pagerank score of the node\n",
    "    pagerank[node] = random_walk + (1 - alpha) * pagerank_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70004ef9-ef61-4945-9718-9a8c2071aeaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pagerank algorithm with standard optimal value for damping factor alpha = 0,85\n",
    "\n",
    "def page_rank(dict_graph, alpha=0.85, n_iterations=5):\n",
    "    # Initialize the pagerank dictionary that will be updated by the pagerank algrithm\n",
    "    pagerank = dict.fromkeys(dict_graph.keys(), 0)\n",
    "    \n",
    "    # All nodes of the graph in a list\n",
    "    nodes = list(dict_graph.keys())\n",
    "    \n",
    "    # Start iterating the algorithm\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        # For each node update the pagerank dictionary --> execute algorithm\n",
    "        for node in tqdm(nodes):\n",
    "            update_pagerank(dict_graph, node, alpha, pagerank)\n",
    "            \n",
    "        if i == 0:\n",
    "            # In the first iteration we save all dict values for next iterations comparisons\n",
    "            prev = list(pagerank.values())\n",
    "        else:\n",
    "            # Tracking how many values converge\n",
    "            count = 0\n",
    "            for pr, actual in zip(prev, list(pagerank.values())):\n",
    "                if pr == actual:\n",
    "                    count += 1\n",
    "            print(\"Convergence for --> \" + str(count) + \" values.\")\n",
    "            # Update the previous values list\n",
    "            prev = list(pagerank.values())\n",
    "            \n",
    "    # Return the pagerank dictionary obtained running the algorithm \"n_iterations\" times\n",
    "    return pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "305e37e1-c32d-45ba-9a60-ce6006d94012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1043/1043 [00:00<00:00, 3992.37it/s]\n",
      "100%|██████████| 1043/1043 [00:00<00:00, 4714.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for --> 595 values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1043/1043 [00:00<00:00, 4714.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for --> 676 values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1043/1043 [00:00<00:00, 4778.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for --> 695 values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1043/1043 [00:00<00:00, 5012.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for --> 697 values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = page_rank(d_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464eae7-5352-4065-841f-c29e847a46b5",
   "metadata": {},
   "source": [
    "#### Betweeness\n",
    "\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the Betweeness centrality of node $v$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{2}{|V|^2 - 3|V| + 2} * \\sum_{u, w \\epsilon V \\backslash \\{v\\}} \\frac{g_{u w}^v}{g_{uw}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "with $g_{uw}$ the shortest path that connects nodes $u$ and $w$ and $g_{u w}^v$ the set of those shortest paths between u and w that contain node $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c43305d7-4ac1-4562-8cb8-ddc7dc65091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a class to manage a queue\n",
    "\n",
    "class MyQueue:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.holder = []\n",
    "\n",
    "    def enqueue(self,val):\n",
    "        self.holder.append(val)\n",
    "\n",
    "    def dequeue(self):\n",
    "        val = None\n",
    "        try:\n",
    "            val = self.holder[0]\n",
    "            if len(self.holder) == 1:\n",
    "                self.holder = []\n",
    "            else:\n",
    "                self.holder = self.holder[1:]   \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return val  \n",
    "\n",
    "    def IsEmpty(self):\n",
    "        result = False\n",
    "        if len(self.holder) == 0:\n",
    "            result = True\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b16d8f87-e1a3-47e4-b2e6-c768e51e732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a modified BFS version that computes all the possible shortest path between \"start\" node and \n",
    "# \"end\" node, taking into account the dijkstra distance computed\n",
    "\n",
    "def BFS(graph, start, end, min_dijk):\n",
    "    \n",
    "    # Initialize the queue, final list of paths and weigths variable\n",
    "    q = MyQueue()\n",
    "    final = []\n",
    "    weights = 0\n",
    "    \n",
    "    # Initialize the path\n",
    "    temp_path = [start]\n",
    "    \n",
    "    q.enqueue(temp_path)\n",
    "    \n",
    "    # Iterating until the queue is empty \n",
    "    while q.IsEmpty() == False:\n",
    "        tmp_path = q.dequeue()\n",
    "        last_node = tmp_path[len(tmp_path)-1]\n",
    "    \n",
    "        # If the last node is our end node --> check the sum weights and if it is equal to minimum Dijkstra distance --> this is a correct minimum path \n",
    "        if last_node == end:\n",
    "            for i in range(len(tmp_path)-1):\n",
    "                weights += graph[tmp_path[i]][tmp_path[i+1]][\"weight\"]\n",
    "            if weights == min_dijk:\n",
    "                final.append(tmp_path)\n",
    "        # Enqueue new path to analyze in the queue\n",
    "        for link_node in graph[last_node]:\n",
    "            if link_node not in tmp_path:\n",
    "                new_path = tmp_path + [link_node]\n",
    "                q.enqueue(new_path)\n",
    "                \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0a0f2bc-745c-45e7-9838-257798a9a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = (\"2008-11-01\",\"2008-11-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e50a5d4-b322-4215-a8f7-bc6203354c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_small = get_graph(time_interval=interval, file=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3d9a13e-eec3-41a0-aff5-fb0e4ca35f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 833 nodes and 909 edges\n"
     ]
    }
   ],
   "source": [
    "print(graph_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0c0665d-729c-4e7a-a705-c8d753e9b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_small = nx.to_dict_of_dicts(graph_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4df9da14-e959-4a37-9864-1ba0c28f7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = '12379'\n",
    "fine = '32990'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f7d8405-0a87-4241-bb47-acc08f59fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_nodes , nodes_distances = shortest_path_Dijkstra(d_small, inizio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1f3dd8c-2fb6-4019-a659-3ac48effcec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peso totale con cui vado da '18313' a \"19964\"\n",
    "min_dis_dijk = nodes_distances[fine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "452cac3e-593c-47d2-8698-b9d20d53d470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12379', '32990']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path completo dall'inizio alla fine\n",
    "nodes_shortest_path(prev_nodes, inizio, fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39304b37-a41c-4b4d-872c-6460c549a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_min_paths = BFS(d_small, inizio,fine, min_dis_dijk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3db4ea43-205f-4b88-a97d-383314b64d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12379', '32990']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_all_min_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e51e9c76-1dc1-462d-aa22-2f503cd3c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweeness(dict_graph, v):\n",
    "    \n",
    "    # Create a list with all the nodes except the one considered\n",
    "    nodes = list(dict_graph.keys())\n",
    "    nodes.remove(v)\n",
    "    \n",
    "    # Create the two terms of the formula\n",
    "    fraction = 0\n",
    "    const = (2 / ((n_users(dict_graph))**2 - 3*(n_users(dict_graph)) + 2))\n",
    "    \n",
    "    # Iterating the list with a double for-loop\n",
    "    for u in tqdm(nodes):\n",
    "        for w in nodes:\n",
    "            g_u_v_w = 0\n",
    "            g_u_w = 0\n",
    "            \n",
    "            # Take lenght of the shortest path between u and w\n",
    "            previous_nodes, nodes_dist = shortest_path_Dijkstra(dict_graph, u)\n",
    "            dist_dijk = nodes_dist[w]\n",
    "            \n",
    "            # All the min paths\n",
    "            all_min_path = BFS(dict_graph, u, w, dist_dijk)\n",
    "            # Number of paths between u and w\n",
    "            g_u_w += len(all_min_path)\n",
    "            # Number of paths that contains v between u and w\n",
    "            g_u_v_w += len([path for path in all_min_path for node in path if node in path and node == v])\n",
    "            \n",
    "        # Compute the sum of the fractions\n",
    "        if g_u_w != 0:\n",
    "            fraction += g_u_v_w / g_u_w\n",
    "            \n",
    "        print(fraction*const)\n",
    "        # Re-initialize the terms\n",
    "        g_u_v_w = 0\n",
    "        g_u_w = 0\n",
    "            \n",
    "    return fraction * const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e0dd0-ee2b-4b40-925d-6beebff26393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/832 [00:22<5:17:24, 22.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/832 [00:46<5:19:54, 23.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/832 [01:10<5:29:02, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/832 [01:34<5:25:26, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/832 [01:57<5:26:29, 23.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/832 [02:22<5:29:59, 23.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 7/832 [02:47<5:33:45, 24.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 8/832 [03:12<5:36:20, 24.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/832 [03:37<5:40:18, 24.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/832 [04:03<5:41:31, 24.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 11/832 [04:28<5:43:25, 25.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 12/832 [04:54<5:45:18, 25.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/832 [05:19<5:46:38, 25.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14/832 [05:48<5:59:45, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/832 [06:17<6:08:43, 27.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/832 [06:42<6:02:18, 26.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 17/832 [07:07<5:55:22, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "betweeness(d_small, '12379')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "302fb6e4-12fb-4304-b97c-c6dac18fa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F2_BestUser(node, time_interval, metric = 4):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    A user/node\n",
    "    The graph on which to perform the analysis.\n",
    "    A tuple of two dates in ISO format representing an interval of time, e.g. (2015-12-04, 2016-12-04) \n",
    "    An integer corresponding to the following metrics: \n",
    "      1 -> Betweeness \n",
    "      2 -> PageRank\n",
    "      3 -> ClosenessCentrality \n",
    "      4 -> DegreeCentrality\n",
    "      \n",
    "    Output:\n",
    "    The value of the given metric applied over the complete graph for the given interval of time.\n",
    "    \"\"\"\n",
    "    \n",
    "    _, dict_graph = build_merged_graph(time_interval)\n",
    "    \n",
    "    if metric == 1:\n",
    "        return betweeness(dict_graph, node)\n",
    "    elif metric == 2:\n",
    "        return page_rank(dict_graph)[node]\n",
    "    elif metric == 3:\n",
    "        return norm_closeness_centrality(dict_graph, node)\n",
    "    elif metric == 4:\n",
    "        return degree_centrality(dict_graph, node)\n",
    "    else:\n",
    "        \"The metric selected doesn't exist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b577dee-4930-401b-93b6-bbf3209c90dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00065\n"
     ]
    }
   ],
   "source": [
    "F2_BestUser('12379', (\"2008-11-01\",\"2008-11-02\"), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97409a4-a7e9-4ba1-bd72-81f5d3402cbd",
   "metadata": {},
   "source": [
    "### Functionality 3 - Shortest Ordered Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c925e63-bd4b-4dc7-93b8-3a37a215ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F3_ShortestRoute(TimeInterval, UserSequence, FirstLastUser):\n",
    "   \"\"\"\n",
    "   Input:\n",
    "   \n",
    "   TimeInterval -> An interval of time\n",
    "   UserSequence -> A sequence of users p = [u_2, ..., u_n-1]\n",
    "   FirstLastUser -> Tuple (u_1, u_n) of initial user u_1 and an end user u_n\n",
    "   \n",
    "   Output:\n",
    "   The shortest walk that goes from user p_j to p_n, and that visits in order the nodes in p\n",
    "   \"\"\"\n",
    "   \n",
    "   # generating graph\n",
    "   _, d_merge = build_merged_graph(time_interval)\n",
    "   \n",
    "   # initializing the list containing the shortest distances between users\n",
    "   Walk = []\n",
    "   \n",
    "   # computing the actual list of users on which the path is computed\n",
    "   start_user_idx = UserSequence.index(FirstLastUser[0])\n",
    "   end_user_idx = UserSequence.index(FirstLastUser[1])\n",
    "   ActualUserSequence = UserSequence[start_user_idx:end_user_idx]\n",
    "   \n",
    "   # cycling though the ActualUserSequence input until the user before the last one\n",
    "   for user in range(len(ActualUserSequence[:-1])): \n",
    "      start_user = ActualUserSequence[user]\n",
    "      end_user = ActualUserSequence[user + 1]\n",
    "      previous_nodes, nodes_dist = shortest_path_Dijkstra(d_merge, start_user) # finding the shortest path\n",
    "      \n",
    "      distance = nodes_dist[end_user]\n",
    "      \n",
    "      # checking if nodes are disconnected\n",
    "      if distance  == float('inf'): \n",
    "         print(\"Not possible\")\n",
    "         break\n",
    "      else:\n",
    "         Walk.append(distance) #appending distance to the walk list\n",
    "\n",
    "   return(sum(Walk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8235c8e7-3742-4004-ac7b-bd49e722aa56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.25"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F3_ShortestRoute((\"2014-01-01\",\"2014-01-03\"), [\"780824\", \"576786\", '577485'], (\"780824\", '577485'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c4ea3b-5416-4c1e-a702-933a72e6206f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Functionality 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "954bd6a6-7763-424d-80d1-142cab6600bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a modified BFS version that computes all the possible shortest path between \"start\" node and \n",
    "# \"end\" node\n",
    "\n",
    "def BFS_F4(graph, start, end):\n",
    "    \n",
    "    # Initialize the queue, final list of paths and weigths variable\n",
    "    q = MyQueue()\n",
    "    final = []\n",
    "    weights = 0\n",
    "    \n",
    "    # Initialize the path\n",
    "    temp_path = [start]\n",
    "    \n",
    "    q.enqueue(temp_path)\n",
    "    \n",
    "    # Iterating until the queue is empty \n",
    "    while q.IsEmpty() == False:\n",
    "        tmp_path = q.dequeue()\n",
    "        last_node = tmp_path[len(tmp_path)-1]\n",
    "    \n",
    "        # If the last node is our end node --> check the sum weights and if it is equal to minimum Dijkstra distance --> this is a correct minimum path \n",
    "        if last_node == end:\n",
    "            final.append(tmp_path)\n",
    "        # Enqueue new path to analyze in the queue\n",
    "        for link_node in graph[last_node]:\n",
    "            if link_node not in tmp_path:\n",
    "                new_path = tmp_path + [link_node]\n",
    "                q.enqueue(new_path)\n",
    "                \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "8a5e11e9-0f65-4629-8fdf-399441ee3d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F4_DisconnectingGraphs(timeInterval_X, timeInterval_Y, *args):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Two different intervals of time (disjoint or not)\n",
    "    Optionally: two users which are unique to each interval of time, otherwise this two users are randomly selected\n",
    "\n",
    "    Output:\n",
    "    The minimum number of links required to disconnect the two users.\n",
    "    \"\"\"\n",
    "\n",
    "    # generating graphs\n",
    "    gX, dX = build_merged_graph(timeInterval_X)\n",
    "    gY, dY = build_merged_graph(timeInterval_Y)\n",
    "    \n",
    "    # user buisness\n",
    "    for node in [*gX.nodes]:\n",
    "        if degree(gX, node) < 4:\n",
    "            gX.remove_node(node)\n",
    "\n",
    "    for node in [*gY.nodes]:\n",
    "        if degree(gY, node) < 4:\n",
    "            gY.remove_node(node)\n",
    "\n",
    "    sX = {*gX.nodes}\n",
    "\n",
    "    sY = {*gY.nodes}\n",
    "\n",
    "    justY = set.difference(sY, sX)\n",
    "    justX = set.difference(sX, sY)\n",
    "\n",
    "    G = nx.compose(gX, gY)\n",
    "    dG = nx.to_dict_of_dicts(G)\n",
    "    # searching paths\n",
    "    try:\n",
    "        tmp = justX.pop() # temporay varible for storing a random user\n",
    "        while not dX[tmp].values(): # discarding unconnected user\n",
    "            tmp = justX.pop()\n",
    "        userX = tmp\n",
    "        tmp = justY.pop() # temporay varible for storing a random user\n",
    "        while not dY[tmp].values(): # discarding unconnected user\n",
    "            tmp = justY.pop()\n",
    "        userY = tmp\n",
    "\n",
    "        _, Distance = shortest_path_Dijkstra(dG, userX)\n",
    "\n",
    "        while Distance[userY] == float('inf'):\n",
    "            tmp = justX.pop() # temporay varible for storing a random user\n",
    "            while not dX[tmp].values(): # discarding unconnected user\n",
    "                tmp = justX.pop()\n",
    "            userX = tmp\n",
    "            tmp = justY.pop() # temporay varible for storing a random user\n",
    "            while not dY[tmp].values(): # discarding unconnected user\n",
    "                tmp = justY.pop()\n",
    "            userY = tmp\n",
    "\n",
    "            _, Distance = shortest_path_Dijkstra(dG, userX)\n",
    "\n",
    "        Paths = BFS_F4(dG, userX, userY)\n",
    "\n",
    "    except KeyError:\n",
    "        print(\"No paths availible\")\n",
    "        \n",
    "    # removing the first and last element of the list, i.e. userX/Y\n",
    "    Joined = []\n",
    "    for i in range(len(Paths)):\n",
    "        Paths[i] = Paths[i][1:-1]\n",
    "        Joined = Joined + Paths[i]\n",
    "\n",
    "    MyCount = Counter(Joined)\n",
    "\n",
    "    links = len(Paths) + 1 - MyCount.most_common()[0][1]\n",
    "    return(links) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "d198fcff-5429-45fc-9b3a-b59edf93cfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F4_DisconnectingGraphs((\"2008-11-01 00:00\",\"2008-11-02 00:00\"), (\"2008-11-02 00:00\",\"2008-11-03 00:00\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592a0a3-393c-43ae-989a-24c519555c41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Algorithmic question\n",
    "\n",
    "For performance reason, I decided to build a dictionary with as keys the kids and as values the enemies of a specific kid. We can assume that the data is given in this format, so we don't calculate the time complexity for building this data structure.\n",
    "\n",
    "I will show anyway the code where I build this dictionary, starting from two lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "70892928-f7b0-44d3-8437-013ce22d5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kids = [1,2,3,4,5,6,7,8,9,10]\n",
    "pairs = [(1,2), (3,4), (7,8), (5,7), (2,10), (8,9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9f9c2a02-4c10-43e4-91b2-0f8551ec68c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary with keys the kids and as values the list of enemies kids\n",
    "fight_dict = { kid:[] for kid in kids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bdff1245-0c56-4801-ae16-9e601c49d843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: [], 10: []}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fight_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1931b1f7-4e12-46e5-b130-97fc01af65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the dictionary\n",
    "for pair in pairs:\n",
    "    if pair[1] not in fight_dict[pair[0]]:\n",
    "        fight_dict[pair[0]].append(pair[1])\n",
    "    if pair[0] not in fight_dict[pair[1]]:\n",
    "        fight_dict[pair[1]].append(pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1f4129ea-5d95-4d82-95ab-fa18b20730cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [2],\n",
       " 2: [1, 10],\n",
       " 3: [4],\n",
       " 4: [3],\n",
       " 5: [7],\n",
       " 6: [],\n",
       " 7: [8, 5],\n",
       " 8: [7, 9],\n",
       " 9: [8],\n",
       " 10: [2]}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fight_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e56daa-0434-4784-b279-dc6f42d56f1c",
   "metadata": {},
   "source": [
    "The algorithm will explore the dictionary, each time looking in the same time to the enemies and the dormitories and then decide in which put the kid.\n",
    "\n",
    "The algorithm will return **two empty lists** if there is not possible to have a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "048c72e6-7ce7-4bc0-9bb1-93e5fb6008b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dormitories(fights):\n",
    "    \n",
    "    # Create the two dormitories lists\n",
    "    d1 = []\n",
    "    d2 = []\n",
    "    \n",
    "    # Iterating through the dictionary created\n",
    "    for kid, enemies in fights.items():\n",
    "        # If there is at least one enemy of the kid present in both dormitories --> return two empty lists becouse we can't compleate the dormitories\n",
    "        if any(enemy in d1  for enemy in enemies) and any(enemy in d2  for enemy in enemies):\n",
    "            return [], []\n",
    "        # If there is an enemy only in the dormitory d2\n",
    "        elif any(enemy in d2  for enemy in enemies):\n",
    "            d1.append(kid)\n",
    "        # Otherwise i put him in d2\n",
    "        else:\n",
    "            d2.append(kid)\n",
    "            \n",
    "    return d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a7925061-b6a4-4fbb-8429-558a9efb0d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "dormitory_1, dormitory_2 = fill_dormitories(fight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "82746585-bc1d-477d-a259-7840c31758b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dormitory 1 is  [2, 4, 7, 9]\n",
      "Dormitory 2 is  [1, 3, 5, 6, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dormitory 1 is \", dormitory_1)\n",
    "print(\"Dormitory 2 is \", dormitory_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e340395-0513-47ff-94c1-1f272c3d9106",
   "metadata": {},
   "source": [
    "#### Analysis of the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75721c-0102-4870-ad32-ef370b7d69f4",
   "metadata": {},
   "source": [
    "The complexity of the algorithm is $O(n*k)$, where $n$ is the number of kids and $k$ is the number of pairs.\n",
    "\n",
    "The algorithm iterates through a dictionary, so it takes $O(n)$. \n",
    "\n",
    "After that, for each iteration it checks all the values (enemies) in the dictionary and it will takes $O(k)$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
