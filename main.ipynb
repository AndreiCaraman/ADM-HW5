{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e40a805-b4c8-4c5f-90e5-f34c40984800",
   "metadata": {},
   "source": [
    "# Exploring StackOverflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633c5809-17a8-4c32-b86c-f4d1219bd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13428b8f-87cc-4e27-860b-3e3d044ed6dc",
   "metadata": {},
   "source": [
    "## Populating the Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f8e26-6488-48a3-b8eb-af1da366985c",
   "metadata": {},
   "source": [
    "Each graph is build independantly from the provided `.txt` files of temporal network of interactions. \\\n",
    "Users are represented as nodes and answers\\comments as edges.\n",
    "\n",
    "The design choices of the following method are:\n",
    "- Using directed graphs. \n",
    "- *Simple* graphs, there are no loops in the graphs. Users who answer to themselves are discarded cases.\n",
    "- Only one attributes is assigned to the edges: weight. The weights are:\n",
    "    - `1` for answers to questions\n",
    "    - `2/3` for comments on questions\n",
    "    - `1/2` for comments to answers\n",
    "- Time resolution is one day.\n",
    "- The graphs are build given a time input to avoid such attribute for the sake of simplicity and robustess.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dcb35e9-e745-4a97-a9ca-c989189dcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_time_int_to_dates(time_interval):\n",
    "    # Convert the time interval in start and end dates \n",
    "    time_interval = tuple(map(datetime.fromisoformat, time_interval)) # converting time interval into datetime format\n",
    "    time_interval = tuple(map(datetime.timestamp, time_interval)) # converting time interval into POSIX timestamp \n",
    "    start_d = int(time_interval[0]) #converting to string to compare with the txt\n",
    "    end_d = int(time_interval[1])\n",
    "    return start_d, end_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01fa146e-6614-4a5c-89eb-a60358889e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_graph(file):\n",
    "    \n",
    "    # Initialize the directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Create mapping of files\n",
    "    map_files = {1: \"sx-stackoverflow-a2q.txt\", 2:\"sx-stackoverflow-c2q.txt\", 3:\"sx-stackoverflow-c2a.txt\"}\n",
    "    \n",
    "    # Select the file chosen, open it and read the lines\n",
    "    with open(map_files[file], \"r\", encoding=\"UTF-8\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            \n",
    "            # Parse the line\n",
    "            elems = line.split(' ')\n",
    "            \n",
    "            # Add the edge to the graph if it is not present\n",
    "            if (elems[0], elems[1]) not in G.edges():\n",
    "                G.add_edge(elems[0], elems[1])\n",
    "                    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79abbfe1-310e-4171-9be1-b6a2434662e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph1_full = get_full_graph(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d85cf-7dc1-48e0-a192-e24fdf55fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2_full = get_full_graph(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e601e7-7b7e-4164-884a-a2a0410d41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph3_full = get_full_graph(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea591c00-2fd7-4634-8e76-aa983b054401",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph1_full)\n",
    "print(graph2_full)\n",
    "print(graph3_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3c5fb-5b1e-44c1-b23e-b6b0728d9a44",
   "metadata": {},
   "source": [
    "#### Write the 3 full graphs into files to save computation each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb4265-d53d-4d27-8571-1f8623640ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(graph1_full, \"graph1_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d9e4e-7f41-4b8e-a75c-3264dd2f5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(graph2_full, \"graph2_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53784624-95e9-4b15-a272-5c17e091e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(graph3_full, \"graph3_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63742a0b-fd36-4aef-87aa-37c561ae9dde",
   "metadata": {},
   "source": [
    "#### Read the 3 full graphs from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032d007-7ac5-4f4b-9ba2-4ce2c5dd3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.read_gml(\"graph1_full\")\n",
    "nx.read_gml(\"graph2_full\")\n",
    "nx.read_gml(\"graph3_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f87aa2-c771-40a2-9064-4b2f2444d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(time_interval, file = 3):\n",
    "    \n",
    "    # Initialize the graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Create mapping of files and mapping of weights\n",
    "    map_files = {1: \"sx-stackoverflow-a2q.txt\", 2:\"sx-stackoverflow-c2q.txt\", 3:\"sx-stackoverflow-c2a.txt\"}\n",
    "    map_weights = {1: 1.0, 2: 2/3, 3: 1/2}\n",
    "    \n",
    "    # Get the start and end dates \n",
    "    start, end = from_time_int_to_dates(time_interval)\n",
    "    \n",
    "    # Select the file chosen, open it and read the lines\n",
    "    with open(map_files[file], \"r\", encoding=\"UTF-8\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            \n",
    "            # Parse the line\n",
    "            elems = line.split(' ')\n",
    "            \n",
    "            # Add to the graph if it is in the time interval\n",
    "            if start <= int(elems[2]) <= end:\n",
    "                # If the edge already exists --> increment the weight, else simply add the new edge\n",
    "                if (elems[0], elems[1]) in G.edges():\n",
    "                    G[elems[0]][elems[1]]['weight'] += float(map_weights[file])\n",
    "                else:\n",
    "                    G.add_edge(elems[0], elems[1], weight = float(map_weights[file]))\n",
    "                    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a9c6c1-f32e-4670-ad92-5bd0bdff80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = (\"2008-11-01\",\"2008-11-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a30b3d-9ea6-4231-9f3e-92a8df1db28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17823525/17823525 [00:11<00:00, 1526653.89it/s]\n"
     ]
    }
   ],
   "source": [
    "graph1 = get_graph(time_interval=interval, file=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba3bc214-1db1-4c99-b8c7-110519bb3449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20268151/20268151 [00:12<00:00, 1595533.58it/s]\n"
     ]
    }
   ],
   "source": [
    "graph2 = get_graph(time_interval=interval, file=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714d350c-7ab9-42aa-9223-15c6f0a7db31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25405374/25405374 [00:16<00:00, 1549330.36it/s]\n"
     ]
    }
   ],
   "source": [
    "graph3 = get_graph(time_interval=interval, file=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c58c22-a182-4231-b5e7-79516bc2289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 4668 nodes and 10758 edges\n",
      "DiGraph with 1111 nodes and 1177 edges\n",
      "DiGraph with 3070 nodes and 5990 edges\n"
     ]
    }
   ],
   "source": [
    "print(graph1)\n",
    "print(graph2)\n",
    "print(graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2316458-1e10-4fa5-8775-96ac64a07bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = nx.to_dict_of_dicts(graph1)\n",
    "d2 = nx.to_dict_of_dicts(graph2)\n",
    "d3 = nx.to_dict_of_dicts(graph3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e418e61-18ae-4ca3-b099-e2162127e3a2",
   "metadata": {},
   "source": [
    "### Merging the graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8c473-b071-4a5a-8f01-d0597e1ff29e",
   "metadata": {},
   "source": [
    "This function will merge two graphs that were obtained by the function **get_graph()** with the same time interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dea53ebc-8ba8-4beb-ba6c-fe2985e52564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_graph(graph_1, graph_2):\n",
    "    \n",
    "    # Iterate over the edges from the second graph\n",
    "    for edge_2 in graph_2.edges(data = True):\n",
    "        # If the edge of graph 2 is also in graph 1, only sum weights\n",
    "        if (edge_2[0],edge_2[1]) in graph_1.edges():\n",
    "            graph_1[edge_2[0]][edge_2[1]]['weight'] += float(edge_2[2]['weight'])\n",
    "        # Else add the edge of graph 2 also in graph 1\n",
    "        else:\n",
    "            graph_1.add_edge(edge_2[0], edge_2[1], weight = float(edge_2[2]['weight']))\n",
    "            \n",
    "    return graph_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42cc4687-2d01-48f7-90e8-e9adfa2301ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged_graph(graph1, graph2)\n",
    "merged = merged_graph(merged, graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298b0936-2f34-4950-9a99-daf15e2c95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 5134 nodes and 17414 edges\n"
     ]
    }
   ],
   "source": [
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32daafc8-c3ff-4bc1-8a66-29d7cbbc104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_merge = nx.to_dict_of_dicts(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3198d9-4c5d-49db-a906-8dbff551a931",
   "metadata": {},
   "source": [
    "### Functionality 1 - Get the overall features of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52219954-599c-451e-b611-805763fb621b",
   "metadata": {},
   "source": [
    "Graph density/sprcity is computed as defined in *\"Introduction to Algorithms\" by Cormern, Leiserson, Rivest, and Stein*: \\\n",
    "A graph $G = (E, V)$, with $E$ denoting the edges and $V$ denoting the vertices,  is sparse if $|E| << |V|^2$ and dense if $|E|$ is close to $|V|$. \\\n",
    "And so if $|E|$ differs an order of magnitude from $|V|$ the graph is considered sparse, otherwise it is dense.\n",
    "The density degree expression is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{|V|}{|E|(|E| - 1)} \\approx \\frac{|V|}{|E|^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44c212be-1f90-4d00-b0cd-a1f1f2bd3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: a boolean True/False\n",
    "\n",
    "def directed(dict_graph):\n",
    "    direct = False\n",
    "    # Iterating through the dictionary items\n",
    "    for node, neighbours in dict_graph.items():\n",
    "        # For each list of adjacency of node\n",
    "        for neighbour in list(neighbours.keys()):\n",
    "            # If the node is not present in the adj list of his neighbours --> break\n",
    "            if node not in list(dict_graph[neighbour].keys()):\n",
    "                direct = True\n",
    "                break\n",
    "    return direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec0d17b4-3d64-47ba-aecb-85220bc15ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: number of nodes in the graph\n",
    "\n",
    "def n_users(dict_graph):\n",
    "    # Return number of keys\n",
    "    return len(dict_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2821b314-94dc-4cf2-8e15-8eee0e212945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: number of edges in the graph\n",
    "\n",
    "# For this implementation we considered the \"out-degree\" = number of edges coming out from the node \n",
    "def n_interactions(dict_graph):\n",
    "    # Sum the length of lists of edges\n",
    "    n_int = 0\n",
    "    for neighbour in dict_graph.values():\n",
    "        n_int += len(list(neighbour.keys()))\n",
    "    return n_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6de77e33-28fe-4fdc-a516-bb9c27d1a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: average number of links for nodes\n",
    "\n",
    "def average_n_links(dict_graph):\n",
    "    return n_interactions(dict_graph) / n_users(dict_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e876a7e4-104c-4f63-b848-11d37ea7fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_OverallFeatures(dict_graph):\n",
    "    \"\"\"\n",
    "    Input: One of the 3 graphs in dictionary format\n",
    "\n",
    "    Output:\n",
    "      Whether the graph is directed or not\n",
    "      Number of users\n",
    "      Number of answers/comments\n",
    "      Average number of links per user\n",
    "      Density degree of the graph\n",
    "      Whether the graph is sparse or dense\n",
    "    \"\"\"\n",
    "    \n",
    "    # quering if the graph is directed\n",
    "    Directed = directed(dict_graph)\n",
    "    \n",
    "    # using a variable to print the output\n",
    "    if Directed: \n",
    "        IsDirectedPrint = 'directed'\n",
    "    else:\n",
    "        IsDirectedPrint = 'undirected'\n",
    "        \n",
    "    # computing the number of users\n",
    "    NofUsers = n_users(dict_graph) \n",
    "    \n",
    "    # computing the number of interactions\n",
    "    NofInteractions = n_interactions(dict_graph)\n",
    "    \n",
    "    # computing the avarege number of links per user\n",
    "    AvgUserLinks = average_n_links(dict_graph)\n",
    "    \n",
    "    # computing density degree\n",
    "    DensityDegree = NofInteractions / NofUsers**2\n",
    "    \n",
    "    # evaluating sparsity/density\n",
    "    if NofUsers / NofInteractions**2 < 10:\n",
    "        SparseDense = 'sparse'\n",
    "    else:\n",
    "        SparseDense = 'dense'\n",
    "        \n",
    "    # print the results\n",
    "    print(f\"The input graph is -> {IsDirectedPrint}\")\n",
    "    print(f\"Number of users -> {NofUsers}\")\n",
    "    print(f\"Number of answers/comments -> {NofInteractions}\")\n",
    "    print(f\"Average number of links per user -> {AvgUserLinks:.2}\")\n",
    "    print(f\"Density degree -> {DensityDegree: .2}\")\n",
    "    print(f\"The graph is -> {SparseDense}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fd84ba2-5d0e-4890-a02a-5d8fa389a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input graph is -> directed\n",
      "Number of users -> 4668\n",
      "Number of answers/comments -> 10758\n",
      "Average number of links per user -> 2.3\n",
      "Density degree ->  0.00049\n",
      "The graph is -> sparse\n"
     ]
    }
   ],
   "source": [
    "F1_OverallFeatures(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c082fc5-e279-4ed4-aa69-ef9435efe06e",
   "metadata": {},
   "source": [
    "### Functionality 2 - Find the best users!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114fc890-f318-422f-9cd0-7d649dd46a6e",
   "metadata": {},
   "source": [
    "#### Degree centrality\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the normalized degree centrality of node $v$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d_v}{|V|-1} \\approx \\frac{d_v}{|V|}\n",
    "\\end{equation}\n",
    "\n",
    "with $d_v$ the degree of the node $v$, i.e. the number of edges incident to the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32c83582-ab3e-47e1-864f-124be4f1bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the degree as \"out-degree\"\n",
    "def degree(dict_graph, node):\n",
    "    return len(list(dict_graph[node].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffc2ca18-61b9-4fe9-afe5-fbaa9b18aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the degree as \"in-degree\"\n",
    "def in_degree(dict_graph, node):\n",
    "    out = 0\n",
    "    for u in list(dict_graph.keys()):\n",
    "        if u != node and (node in list(dict_graph[u].keys())):\n",
    "            out += 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83655f9a-1eea-4b88-96e6-802b18206f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the definition\n",
    "def degree_centrality(dict_graph, node):\n",
    "    out = degree(dict_graph, node) / n_interactions(dict_graph)\n",
    "    print(f\"{out:.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b48406a-a9ec-4841-971a-5cd472374042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018\n"
     ]
    }
   ],
   "source": [
    "degree_centrality(d1, \"30155\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e52b09d0-6513-40ae-9d13-0dddf34cc31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.3e-05\n"
     ]
    }
   ],
   "source": [
    "degree_centrality(d1, \"4120\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45da09-30c8-4288-b7d4-0744200af52a",
   "metadata": {},
   "source": [
    "#### Closeness centrality\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the normalized closeness centrality of node $v$ is:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{|V|-1}{\\sum_{u \\epsilon V} d(v,u)} \\approx \\frac{|V|}{\\sum_{u \\epsilon V} d(v,u)}\n",
    "\\end{equation}\n",
    "\n",
    "with $d(v,u)$ the distance between nodes $v$ and $u$, that is the length of a shortest path between $v$ and $u$.\\\n",
    "As a design choice $d(v,u)$ is taken as the inverse of the weight of the edge of $(v,u)$, this leads to an inverse relationship between interaction and distances: the more a user posts, the closer he gets to the comunity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "777470dc-f01d-45cf-8f23-a38c6242e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outgoing_edges(dict_graph, node):\n",
    "    return list(dict_graph[node].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c16d0278-6ace-4ba3-989d-f2d3b103866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts, the start node\n",
    "# Output: two dictionaries: the first memorize the nodes involved in the shortest paths, the second is the shortest path in distance terms.\n",
    "# Pseudocode from: https://en.wikipedia.org/wiki/Dijkstra's_algorithm#Pseudocode\n",
    "\n",
    "def shortest_path_Dijkstra(dict_graph, node):\n",
    "    \n",
    "    # Initialize two dictionaries to track visited nodes and weights\n",
    "    nodes_dist = dict.fromkeys(dict_graph.keys(), float('inf'))\n",
    "    \n",
    "    # Initialize another dictionary that track the nodes in the shortest path\n",
    "    previous_nodes = dict.fromkeys(dict_graph.keys())\n",
    "    \n",
    "    # Create a list of the unvisited nodes \n",
    "    unvisited = list(dict_graph.keys())\n",
    "    \n",
    "    # First update on the selected node\n",
    "    nodes_dist[node] = 0\n",
    "    \n",
    "    # Start iterating until each node is visited\n",
    "    while(unvisited):\n",
    "        \n",
    "        # Select the current min_node with a for-loop\n",
    "        min_node = None\n",
    "        for n in unvisited:\n",
    "            if min_node == None:\n",
    "                min_node = n\n",
    "            elif nodes_dist[n] < nodes_dist[min_node]:\n",
    "                min_node = n\n",
    "            \n",
    "        # Update distances of the current min_node's neighbors\n",
    "        neighbors = get_outgoing_edges(dict_graph, min_node)\n",
    "        for neighbor in neighbors:\n",
    "            # Calculate the possible update to the shortest path and check if it is < then the actual distance\n",
    "            possible_update = nodes_dist[min_node] + dict_graph[min_node][neighbor]['weight']\n",
    "            if possible_update < nodes_dist[neighbor]:\n",
    "                nodes_dist[neighbor] = possible_update\n",
    "                # We also update the best path to the current node\n",
    "                previous_nodes[neighbor] = min_node\n",
    "        \n",
    "        # Remove the current min_node from the unvisited list\n",
    "        unvisited.remove(min_node)\n",
    "    \n",
    "    return previous_nodes, nodes_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58f8853f-b26c-4e29-9c96-739d4fd8c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_shortest_path(previous_nodes, start_node, target_node):\n",
    "    path = []\n",
    "    node = target_node\n",
    "    \n",
    "    while node != start_node:\n",
    "        if node == None:\n",
    "            return []\n",
    "        path.append(node)\n",
    "        node = previous_nodes[node]\n",
    "        \n",
    "    # Add the start node manually\n",
    "    path.append(start_node)\n",
    "    \n",
    "    return list(reversed(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1a63c496-a303-4f36-a0fb-dabe51f48598",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_nodes , nodes_distances = shortest_path_Dijkstra(d_merge, '18313')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8e403306-33c0-443a-abb7-9f378f5ea1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peso totale con cui vado da '18313' a \"19964\"\n",
    "min_dis_dijk = nodes_distances[\"19964\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fa3e46eb-578a-46f6-b214-dbe145d1c273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['18313', '28258', '6782', '19964']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path completo dall'inizio alla fine\n",
    "nodes_shortest_path(prev_nodes,'18313', \"19964\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e433537-64c2-4ca1-b45b-38a157bdea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_closeness_centrality(dict_graph, v):\n",
    "    \n",
    "    # Create a list with all the nodes except the one considered\n",
    "    nodes = list(dict_graph.keys())\n",
    "    nodes.remove(v)\n",
    "    \n",
    "    # Iterate and calculate the denominator adding all the distances calculated with Dijkstra\n",
    "    denom = 0\n",
    "    _, dists = shortest_path_Dijkstra(dict_graph, v)\n",
    "    \n",
    "    for u in nodes:\n",
    "        denom += dists[u]\n",
    "        \n",
    "    # Return the result\n",
    "    return (n_users(dict_graph)) / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b0601fd-bf3c-4ec6-819c-b915421bf3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_closeness_centrality(d_merge, \"18313\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2fb2bb46-1c44-4d6a-9315-d82a2812a78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_closeness_centrality(d_merge, \"19964\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df06f29-b1a6-496e-8dbb-6d1149e30120",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc2d6ff-a139-4cda-8323-9ec597906d4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "The page rank algorithm will be implemented with Random Surfer Model in which we will use a value $\\alpha$ to adjust all the points in the matrix of edges(a matrix where there are ones if the edge exists and zeros otherwise).\n",
    "\n",
    "The matrix of edges could be full of zeros, so in order to save space in memory, we will not store it. We simply modify a dictionary with as keys the nodes and as values the corrispondant page rank score:\n",
    "\n",
    "The update equation looks like this:\n",
    "\n",
    "\\begin{equation}\n",
    "PageRank(v) = \\frac{\\alpha}{n} + (1-\\alpha) * \\sum_{e_{u,v} \\in E}^{} \\frac{PageRank(u)}{OutDegree(u)}\n",
    "\\end{equation}\n",
    "\n",
    "where $v$ is the target node, $n$ is the number of edges in the graph and $e_{u,v} \\in E$ means that exists an edge between $u$ and $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b3d47064-91dd-4f7b-9d98-51b79c1984d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return a list of all parents of a node\n",
    "\n",
    "def get_parents(dict_graph, node):\n",
    "    out = []\n",
    "    for u in list(dict_graph.keys()):\n",
    "        # Check for each node in which children list appear and append it to the final list\n",
    "        if u != node and (node in list(dict_graph[u].keys())):\n",
    "            out.append(u)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "07dbab77-b9ce-490b-9b71-db72228243bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will return a list of children of a node\n",
    "\n",
    "def get_children(dict_graph, node):\n",
    "    return list(dict_graph[node].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2c32991c-83e9-42fe-b4f0-cb4d08965a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will execute the update to the pagerank dictionary\n",
    "\n",
    "def update_pagerank(dict_graph, node, alpha, pagerank):\n",
    "    \n",
    "    # Take the parents of the node\n",
    "    parents = get_parents(dict_graph, node)\n",
    "    \n",
    "    # Calculate the sum term of the formula\n",
    "    pagerank_sum = sum((pagerank[node] / len(get_children(dict_graph, node))) for node in parents)\n",
    "    \n",
    "    # Calculate the random alpha-dependent term\n",
    "    random_walk = alpha / n_users(dict_graph)\n",
    "    \n",
    "    # Update the pagerank score of the node\n",
    "    pagerank[node] = random_walk + (1 - alpha) * pagerank_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "70004ef9-ef61-4945-9718-9a8c2071aeaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pagerank algorithm with standard optimal value for damping factor alpha = 0,85\n",
    "\n",
    "def page_rank(dict_graph, alpha=0.85, n_iterations=5):\n",
    "    # Initialize the pagerank dictionary that will be updated by the pagerank algrithm\n",
    "    pagerank = dict.fromkeys(dict_graph.keys(), 0)\n",
    "    \n",
    "    # All nodes of the graph in a list\n",
    "    nodes = list(dict_graph.keys())\n",
    "    \n",
    "    # Start iterating the algorithm\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        # For each node update the pagerank dictionary --> execute algorithm\n",
    "        for node in tqdm(nodes):\n",
    "            update_pagerank(dict_graph, node, alpha, pagerank)\n",
    "            \n",
    "        if i == 0:\n",
    "            # In the first iteration we save all dict values for next iterations comparisons\n",
    "            prev = list(pagerank.values())\n",
    "        else:\n",
    "            # Tracking how many values converge\n",
    "            count = 0\n",
    "            for pr, actual in zip(prev, list(pagerank.values())):\n",
    "                if pr == actual:\n",
    "                    count += 1\n",
    "            print(\"Convergence for --> \" + str(count) + \" values.\")\n",
    "            # Update the previous values list\n",
    "            prev = list(pagerank.values())\n",
    "            \n",
    "    # Return the pagerank dictionary obtained running the algorithm \"n_iterations\" times\n",
    "    return pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "305e37e1-c32d-45ba-9a60-ce6006d94012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5134/5134 [00:35<00:00, 146.11it/s]\n",
      "100%|██████████| 5134/5134 [00:34<00:00, 150.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence for --> 1526 values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1021/5134 [00:07<00:29, 137.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16740/880592175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_merge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16740/3349720277.py\u001b[0m in \u001b[0;36mpage_rank\u001b[1;34m(dict_graph, alpha, n_iterations)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# For each node update the pagerank dictionary --> execute algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mupdate_pagerank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpagerank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16740/2483725274.py\u001b[0m in \u001b[0;36mupdate_pagerank\u001b[1;34m(dict_graph, node, alpha, pagerank)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mupdate_pagerank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpagerank\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Take the parents of the node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mparents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_parents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Calculate the sum term of the formula\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpagerank_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpagerank\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_children\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16740/2750294217.py\u001b[0m in \u001b[0;36mget_parents\u001b[1;34m(dict_graph, node)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m# Check for each node in which children list appear and append it to the final list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_graph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result = page_rank(d_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464eae7-5352-4065-841f-c29e847a46b5",
   "metadata": {},
   "source": [
    "#### Betweeness\n",
    "\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the Betweeness centrality of node $v$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{2}{|V|^2 - 3|V| + 2} * \\sum_{u, w \\epsilon V \\backslash \\{v\\}} \\frac{g_{u w}^v}{g_{uw}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "with $g_{uw}$ the shortest path that connects nodes $u$ and $w$ and $g_{u w}^v$ the set of those shortest paths between u and w that contain node $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c43305d7-4ac1-4562-8cb8-ddc7dc65091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a class to manage a queue\n",
    "\n",
    "class MyQueue:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.holder = []\n",
    "\n",
    "    def enqueue(self,val):\n",
    "        self.holder.append(val)\n",
    "\n",
    "    def dequeue(self):\n",
    "        val = None\n",
    "        try:\n",
    "            val = self.holder[0]\n",
    "            if len(self.holder) == 1:\n",
    "                self.holder = []\n",
    "            else:\n",
    "                self.holder = self.holder[1:]   \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return val  \n",
    "\n",
    "    def IsEmpty(self):\n",
    "        result = False\n",
    "        if len(self.holder) == 0:\n",
    "            result = True\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b16d8f87-e1a3-47e4-b2e6-c768e51e732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a modified BFS version that computes all the possible shortest path between \"start\" node and \n",
    "# \"end\" node, taking into account the dijkstra distance computed\n",
    "\n",
    "def BFS(graph, start, end, min_dijk):\n",
    "    \n",
    "    # Initialize the queue, final list of paths and weigths variable\n",
    "    q = MyQueue()\n",
    "    final = []\n",
    "    weights = 0\n",
    "    \n",
    "    # Initialize the path\n",
    "    temp_path = [start]\n",
    "    \n",
    "    q.enqueue(temp_path)\n",
    "    \n",
    "    # Iterating until the queue is empty \n",
    "    while q.IsEmpty() == False:\n",
    "        tmp_path = q.dequeue()\n",
    "        last_node = tmp_path[len(tmp_path)-1]\n",
    "    \n",
    "        # If the last node is our end node --> check the sum weights and if it is equal to minimum Dijkstra distance --> this is a correct minimum path \n",
    "        if last_node == end:\n",
    "            for i in range(len(tmp_path)-1):\n",
    "                weights += graph[tmp_path[i]][tmp_path[i+1]][\"weight\"]\n",
    "            if weights == min_dijk:\n",
    "                final.append(tmp_path)\n",
    "        # Enqueue new path to analyze in the queue\n",
    "        for link_node in graph[last_node]:\n",
    "            if link_node not in tmp_path:\n",
    "                new_path = tmp_path + [link_node]\n",
    "                q.enqueue(new_path)\n",
    "                \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a0a0f2bc-745c-45e7-9838-257798a9a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = (\"2008-11-01\",\"2008-11-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5e50a5d4-b322-4215-a8f7-bc6203354c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17823525/17823525 [00:36<00:00, 491135.92it/s]\n"
     ]
    }
   ],
   "source": [
    "graph_small = get_graph(time_interval=interval, file=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3d9a13e-eec3-41a0-aff5-fb0e4ca35f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 881 nodes and 922 edges\n"
     ]
    }
   ],
   "source": [
    "print(graph_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d0c0665d-729c-4e7a-a705-c8d753e9b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_small = nx.to_dict_of_dicts(graph_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4df9da14-e959-4a37-9864-1ba0c28f7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "inizio = '12379'\n",
    "fine = '32990'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6f7d8405-0a87-4241-bb47-acc08f59fa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_nodes , nodes_distances = shortest_path_Dijkstra(d_small, inizio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f1f3dd8c-2fb6-4019-a659-3ac48effcec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'32990'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16740/2980173956.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# peso totale con cui vado da '18313' a \"19964\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmin_dis_dijk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_distances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: '32990'"
     ]
    }
   ],
   "source": [
    "# peso totale con cui vado da '18313' a \"19964\"\n",
    "min_dis_dijk = nodes_distances[fine]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452cac3e-593c-47d2-8698-b9d20d53d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path completo dall'inizio alla fine\n",
    "nodes_shortest_path(prev_nodes, inizio, fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39304b37-a41c-4b4d-872c-6460c549a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_min_paths = BFS(d_small, inizio,fine, min_dis_dijk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4ea43-205f-4b88-a97d-383314b64d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_min_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e51e9c76-1dc1-462d-aa22-2f503cd3c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def betweeness(dict_graph, v):\n",
    "    \n",
    "    # Create a list with all the nodes except the one considered\n",
    "    nodes = list(dict_graph.keys())\n",
    "    nodes.remove(v)\n",
    "    \n",
    "    # Create the two terms of the formula\n",
    "    fraction = 0\n",
    "    const = (2 / ((n_users(dict_graph))**2 - 3*(n_users(dict_graph)) + 2))\n",
    "    \n",
    "    # Iterating the list with a double for-loop\n",
    "    for u in tqdm(nodes):\n",
    "        for w in nodes:\n",
    "            g_u_v_w = 0\n",
    "            g_u_w = 0\n",
    "            \n",
    "            # Take lenght of the shortest path between u and w\n",
    "            previous_nodes, nodes_dist = shortest_path_Dijkstra(dict_graph, u)\n",
    "            dist_dijk = nodes_dist[w]\n",
    "            \n",
    "            # All the min paths\n",
    "            all_min_path = BFS(dict_graph, u, w, dist_dijk)\n",
    "            # Number of paths between u and w\n",
    "            g_u_w += len(all_min_path)\n",
    "            # Number of paths that contains v between u and w\n",
    "            g_u_v_w += len([path for path in all_min_path for node in path if node in path and node == v])\n",
    "            \n",
    "        # Re-initialize the terms\n",
    "        g_u_w = 0\n",
    "        g_u_v_w = 0\n",
    "        if g_u_w != 0:\n",
    "            fraction += g_u_v_w / g_u_w\n",
    "            \n",
    "    return fraction * const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e7ca68d-c2a8-4653-bd7f-42fa279ee7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/880 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16740/3487946076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbetweeness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_small\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'12379'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16740/1971018845.py\u001b[0m in \u001b[0;36mbetweeness\u001b[1;34m(dict_graph, v)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# Take lenght of the shortest path between u and w\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mprevious_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnodes_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshortest_path_Dijkstra\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mdist_dijk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnodes_dist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16740/2953591820.py\u001b[0m in \u001b[0;36mshortest_path_Dijkstra\u001b[1;34m(dict_graph, node)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmin_node\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mmin_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[1;32melif\u001b[0m \u001b[0mnodes_dist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnodes_dist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin_node\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                 \u001b[0mmin_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "betweeness(d_small, '12379')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "302fb6e4-12fb-4304-b97c-c6dac18fa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F2_BestUser(node, time_interval, metric = 4):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    A user/node\n",
    "    The graph on which to perform the analysis.\n",
    "    A tuple of two dates in ISO format representing an interval of time, e.g. (2015-12-04, 2016-12-04) \n",
    "    An integer corresponding to the following metrics: \n",
    "      1 -> Betweeness \n",
    "      2 -> PageRank\n",
    "      3 -> ClosenessCentrality \n",
    "      4 -> DegreeCentrality\n",
    "      \n",
    "    Output:\n",
    "    The value of the given metric applied over the complete graph for the given interval of time.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the graph from the time interval\n",
    "    graph_1 = get_graph(time_interval, file=1)\n",
    "    graph_2 = get_graph(time_interval, file=2)\n",
    "    graph_3 = get_graph(time_interval, file=3)\n",
    "    merged = merged_graph(graph1, graph2)\n",
    "    merged = merged_graph(merged, graph3)\n",
    "    dict_graph = nx.to_dict_of_dicts(merged)\n",
    "    \n",
    "    if metric == 1:\n",
    "        return betweeness(dict_graph, node)\n",
    "    elif metric == 2:\n",
    "        return page_rank(dict_graph)[node]\n",
    "    elif metric == 3:\n",
    "        return norm_closeness_centrality(dict_graph, node)\n",
    "    elif metric == 4:\n",
    "        return degree_centrality(dict_graph, node)\n",
    "    else:\n",
    "        \"The metric selected doesn't exist.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5b577dee-4930-401b-93b6-bbf3209c90dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17823525/17823525 [00:34<00:00, 517479.92it/s]\n",
      "100%|██████████| 20268151/20268151 [00:38<00:00, 521321.76it/s]\n",
      "100%|██████████| 25405374/25405374 [00:51<00:00, 497165.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00046\n"
     ]
    }
   ],
   "source": [
    "F2_BestUser('12379', (\"2008-11-01\",\"2008-11-02\"), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b84ae87-708b-456d-9cea-1c8d3b70ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quering if the graph is directed\n",
    "    Directed = directed(dict_graph)\n",
    "    \n",
    "    # using a variable to print the output\n",
    "    if Directed: \n",
    "        IsDirectedPrint = 'directed'\n",
    "    else:\n",
    "        IsDirectedPrint = 'undirected'\n",
    "        \n",
    "    # computing the number of users\n",
    "    NofUsers = n_users(dict_graph) \n",
    "    \n",
    "    # computing the number of interactions\n",
    "    NofInteractions = n_interactions(dict_graph)\n",
    "    \n",
    "    # computing the avarege number of links per user\n",
    "    AvgUserLinks = average_n_links(dict_graph)\n",
    "    \n",
    "    # computing density degree\n",
    "    DensityDegree = NofInteractions / NofUsers**2\n",
    "    \n",
    "    # evaluating sparsity/density\n",
    "    if NofUsers / NofInteractions**2 < 10:\n",
    "        SparseDense = 'sparse'\n",
    "    else:\n",
    "        SparseDense = 'dense'\n",
    "        \n",
    "    # print the results\n",
    "    print(f\"The input graph is -> {IsDirectedPrint}\")\n",
    "    print(f\"Number of users -> {NofUsers}\")\n",
    "    print(f\"Number of answers/comments -> {NofInteractions}\")\n",
    "    print(f\"Average number of links per user -> {AvgUserLinks:.2}\")\n",
    "    print(f\"Density degree -> {DensityDegree: .2}\")\n",
    "    print(f\"The graph is -> {SparseDense}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97409a4-a7e9-4ba1-bd72-81f5d3402cbd",
   "metadata": {},
   "source": [
    "### Functionality 3 - Shortest Ordered Route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c925e63-bd4b-4dc7-93b8-3a37a215ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F3_ShortestRoute(TimeInterval, UserSequence, FirstLastUser):\n",
    "   \"\"\"\n",
    "   Input:\n",
    "   \n",
    "   TimeInterval -> An interval of time\n",
    "   UserSequence -> A sequence of users p = [u_2, ..., u_n-1]\n",
    "   FirstLastUser -> Tuple (u_1, u_n) of initial user u_1 and an end user u_n\n",
    "   \n",
    "   Output:\n",
    "   The shortest walk that goes from user p_j to p_n, and that visits in order the nodes in p\n",
    "   \"\"\"\n",
    "   \n",
    "   # generating graph\n",
    "   graph1 = get_graph(time_interval=TimeInterval, file=1)\n",
    "   graph2 = get_graph(time_interval=TimeInterval, file=2)\n",
    "   graph3 = get_graph(time_interval=TimeInterval, file=3)\n",
    "   merged = merged_graph(graph1, graph2)\n",
    "   merged = merged_graph(merged, graph3)\n",
    "   d_merge = nx.to_dict_of_dicts(merged)\n",
    "   \n",
    "   # initializing the list containing the shortest distances between users\n",
    "   Walk = []\n",
    "   \n",
    "   # computing the actual list of users on which the path is computed\n",
    "   start_user_idx = UserSequence.index(FirstLastUser[0])\n",
    "   end_user_idx = UserSequence.index(FirstLastUser[1])\n",
    "   ActualUserSequence = UserSequence[start_user_idx:end_user_idx]\n",
    "   \n",
    "   # cycling though the ActualUserSequence input until the user before the last one\n",
    "   for user in range(len(ActualUserSequence[:-1])): \n",
    "      start_user = ActualUserSequence[user]\n",
    "      end_user = ActualUserSequence[user + 1]\n",
    "      previous_nodes, nodes_dist = shortest_path_Dijkstra(d_merge, start_user) # finding the shortest path\n",
    "      \n",
    "      distance = nodes_dist[end_user]\n",
    "      \n",
    "      # checking if nodes are disconnected\n",
    "      if distance  == float('inf'): \n",
    "         print(\"Not possible\")\n",
    "         break\n",
    "      else:\n",
    "         Walk.append(distance) #appending distance to the walk list\n",
    "\n",
    "   return(sum(Walk))\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8235c8e7-3742-4004-ac7b-bd49e722aa56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.82857142857143"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F3_ShortestRoute((\"2014-01-01\",\"2014-01-03\"), [\"780824\", \"576786\", '577485'], (\"780824\", '577485'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
