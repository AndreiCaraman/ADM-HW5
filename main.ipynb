{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e40a805-b4c8-4c5f-90e5-f34c40984800",
   "metadata": {},
   "source": [
    "# Exploring StackOverflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633c5809-17a8-4c32-b86c-f4d1219bd16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13428b8f-87cc-4e27-860b-3e3d044ed6dc",
   "metadata": {},
   "source": [
    "## Populating the Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f8e26-6488-48a3-b8eb-af1da366985c",
   "metadata": {},
   "source": [
    "Each graph is build independantly from the provided `.txt` files of temporal network of interactions. \\\n",
    "Users are represented as nodes and answers\\comments as edges.\n",
    "\n",
    "The design choices of the following method are:\n",
    "- Using directed graphs. \n",
    "- *Simple* graphs, there are no loops in the graphs. Users who answer to themselves are discarded cases.\n",
    "- Only one attributes is assigned to the edges: weight. The weights are:\n",
    "    - `1` for answers to questions\n",
    "    - `2/3` for comments on questions\n",
    "    - `1/2` for comments to answers\n",
    "- Time resolution is one day.\n",
    "- The graphs are build given a time input to avoid such attribute for the sake of simplicity and robustess.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcb35e9-e745-4a97-a9ca-c989189dcbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_time_int_to_dates(time_interval):\n",
    "    # Convert the time interval in start and end dates \n",
    "    time_interval = tuple(map(datetime.fromisoformat, time_interval)) # converting time interval into datetime format\n",
    "    time_interval = tuple(map(datetime.timestamp, time_interval)) # converting time interval into POSIX timestamp \n",
    "    start_d = int(time_interval[0]) #converting to string to compare with the txt\n",
    "    end_d = int(time_interval[1])\n",
    "    return start_d, end_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fa146e-6614-4a5c-89eb-a60358889e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_graph(file):\n",
    "    \n",
    "    # Initialize the directed graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Create mapping of files\n",
    "    map_files = {1: \"sx-stackoverflow-a2q.txt\", 2:\"sx-stackoverflow-c2q.txt\", 3:\"sx-stackoverflow-c2a.txt\"}\n",
    "    \n",
    "    # Select the file chosen, open it and read the lines\n",
    "    with open(map_files[file], \"r\", encoding=\"UTF-8\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            \n",
    "            # Parse the line\n",
    "            elems = line.split(' ')\n",
    "            \n",
    "            # Add the edge to the graph if it is not present\n",
    "            if (elems[0], elems[1]) not in G.edges():\n",
    "                G.add_edge(elems[0], elems[1])\n",
    "                    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79abbfe1-310e-4171-9be1-b6a2434662e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 11316822/17823525 [08:47<02:49, 38280.09it/s]"
     ]
    }
   ],
   "source": [
    "graph1_full = get_full_graph(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d85cf-7dc1-48e0-a192-e24fdf55fa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2_full = get_full_graph(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e601e7-7b7e-4164-884a-a2a0410d41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph3_full = get_full_graph(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea591c00-2fd7-4634-8e76-aa983b054401",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph1_full)\n",
    "print(graph2_full)\n",
    "print(graph3_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc3c5fb-5b1e-44c1-b23e-b6b0728d9a44",
   "metadata": {},
   "source": [
    "#### Write the 3 full graphs into files to save computation each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cb4265-d53d-4d27-8571-1f8623640ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(graph1_full, \"graph1_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266d9e4e-7f41-4b8e-a75c-3264dd2f5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(graph2_full, \"graph2_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53784624-95e9-4b15-a272-5c17e091e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gml(graph3_full, \"graph3_full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63742a0b-fd36-4aef-87aa-37c561ae9dde",
   "metadata": {},
   "source": [
    "#### Read the 3 full graphs from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032d007-7ac5-4f4b-9ba2-4ce2c5dd3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.read_gml(\"graph1_full\")\n",
    "nx.read_gml(\"graph2_full\")\n",
    "nx.read_gml(\"graph3_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69f87aa2-c771-40a2-9064-4b2f2444d519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(time_interval, file = 3):\n",
    "    \n",
    "    # Initialize the graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Create mapping of files and mapping of weights\n",
    "    map_files = {1: \"sx-stackoverflow-a2q.txt\", 2:\"sx-stackoverflow-c2q.txt\", 3:\"sx-stackoverflow-c2a.txt\"}\n",
    "    map_weights = {1: 1.0, 2: 2/3, 3: 1/2}\n",
    "    \n",
    "    # Get the start and end dates \n",
    "    start, end = from_time_int_to_dates(time_interval)\n",
    "    \n",
    "    # Select the file chosen, open it and read the lines\n",
    "    with open(map_files[file], \"r\", encoding=\"UTF-8\") as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            \n",
    "            # Parse the line\n",
    "            elems = line.split(' ')\n",
    "            \n",
    "            # Add to the graph if it is in the time interval\n",
    "            if start <= int(elems[2]) <= end:\n",
    "                # If the edge already exists --> increment the weight, else simply add the new edge\n",
    "                if (elems[0], elems[1]) in G.edges():\n",
    "                    G[elems[0]][elems[1]]['weight'] += float(map_weights[file])\n",
    "                else:\n",
    "                    G.add_edge(elems[0], elems[1], weight = float(map_weights[file]))\n",
    "                    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a9c6c1-f32e-4670-ad92-5bd0bdff80eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = (\"2008-11-01\",\"2008-11-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12a30b3d-9ea6-4231-9f3e-92a8df1db28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17823525/17823525 [00:10<00:00, 1629136.06it/s]\n"
     ]
    }
   ],
   "source": [
    "graph1 = get_graph(time_interval=interval, file=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba3bc214-1db1-4c99-b8c7-110519bb3449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20268151/20268151 [00:12<00:00, 1667708.46it/s]\n"
     ]
    }
   ],
   "source": [
    "graph2 = get_graph(time_interval=interval, file=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714d350c-7ab9-42aa-9223-15c6f0a7db31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25405374/25405374 [00:15<00:00, 1601281.35it/s]\n"
     ]
    }
   ],
   "source": [
    "graph3 = get_graph(time_interval=interval, file=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c58c22-a182-4231-b5e7-79516bc2289c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 833 nodes and 909 edges\n",
      "DiGraph with 135 nodes and 100 edges\n",
      "DiGraph with 534 nodes and 560 edges\n"
     ]
    }
   ],
   "source": [
    "print(graph1)\n",
    "print(graph2)\n",
    "print(graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2316458-1e10-4fa5-8775-96ac64a07bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = nx.to_dict_of_dicts(graph1)\n",
    "d2 = nx.to_dict_of_dicts(graph2)\n",
    "d3 = nx.to_dict_of_dicts(graph3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e418e61-18ae-4ca3-b099-e2162127e3a2",
   "metadata": {},
   "source": [
    "### Merging the graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b8c473-b071-4a5a-8f01-d0597e1ff29e",
   "metadata": {},
   "source": [
    "This function will merge two graphs that were obtained by the function **get_graph()** with the same time interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dea53ebc-8ba8-4beb-ba6c-fe2985e52564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged_graph(graph_1, graph_2):\n",
    "    \n",
    "    # Iterate over the edges from the second graph\n",
    "    for edge_2 in graph_2.edges(data = True):\n",
    "        # If the edge of graph 2 is also in graph 1, only sum weights\n",
    "        if (edge_2[0],edge_2[1]) in graph_1.edges():\n",
    "            graph_1[edge_2[0]][edge_2[1]]['weight'] += float(edge_2[2]['weight'])\n",
    "        # Else add the edge of graph 2 also in graph 1\n",
    "        else:\n",
    "            graph_1.add_edge(edge_2[0], edge_2[1], weight = float(edge_2[2]['weight']))\n",
    "            \n",
    "    return graph_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42cc4687-2d01-48f7-90e8-e9adfa2301ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged_graph(graph1, graph2)\n",
    "merged = merged_graph(merged, graph3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298b0936-2f34-4950-9a99-daf15e2c95c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiGraph with 1044 nodes and 1542 edges\n"
     ]
    }
   ],
   "source": [
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32daafc8-c3ff-4bc1-8a66-29d7cbbc104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_merge = nx.to_dict_of_dicts(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3198d9-4c5d-49db-a906-8dbff551a931",
   "metadata": {},
   "source": [
    "### Functionality 1 - Get the overall features of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52219954-599c-451e-b611-805763fb621b",
   "metadata": {},
   "source": [
    "Graph density/sprcity is computed as defined in *\"Introduction to Algorithms\" by Cormern, Leiserson, Rivest, and Stein*: \\\n",
    "A graph $G = (E, V)$, with $E$ denoting the edges and $V$ denoting the vertices,  is sparse if $|E| << |V|^2$ and dense if $|E|$ is close to $|V|$. \\\n",
    "And so if $|E|$ differs an order of magnitude from $|V|$ the graph is considered sparse, otherwise it is dense.\n",
    "The density degree expression is:\n",
    "\n",
    "\\begin{equation}\n",
    "2\\frac{|V|}{|E|(|E| - 1)} \\approx 2\\frac{|V|}{|E|^2}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44c212be-1f90-4d00-b0cd-a1f1f2bd3779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: a boolean True/False\n",
    "\n",
    "def directed(dict_graph):\n",
    "    direct = False\n",
    "    # Iterating through the dictionary items\n",
    "    for node, neighbours in dict_graph.items():\n",
    "        # For each list of adjacency of node\n",
    "        for neighbour in list(neighbours.keys()):\n",
    "            # If the node is not present in the adj list of his neighbours --> break\n",
    "            if node not in list(dict_graph[neighbour].keys()):\n",
    "                direct = True\n",
    "                break\n",
    "    return direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec0d17b4-3d64-47ba-aecb-85220bc15ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: number of nodes in the graph\n",
    "\n",
    "def n_users(dict_graph):\n",
    "    # Return number of keys\n",
    "    return len(dict_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2821b314-94dc-4cf2-8e15-8eee0e212945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: number of edges in the graph\n",
    "\n",
    "# For this implementation we considered the \"out-degree\" = number of edges coming out from the node \n",
    "def n_interactions(dict_graph):\n",
    "    # Sum the length of lists of edges\n",
    "    n_int = 0\n",
    "    for neighbour in dict_graph.values():\n",
    "        n_int += len(list(neighbour.keys()))\n",
    "    return n_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6de77e33-28fe-4fdc-a516-bb9c27d1a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts\n",
    "# Output: average number of links for nodes\n",
    "\n",
    "def average_n_links(dict_graph):\n",
    "    return n_interactions(dict_graph) / n_users(dict_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e876a7e4-104c-4f63-b848-11d37ea7fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_OverallFeatures(dict_graph):\n",
    "    \"\"\"\n",
    "    Input: One of the 3 graphs in dictionary format\n",
    "\n",
    "    Output:\n",
    "      Whether the graph is directed or not\n",
    "      Number of users\n",
    "      Number of answers/comments\n",
    "      Average number of links per user\n",
    "      Density degree of the graph\n",
    "      Whether the graph is sparse or dense\n",
    "    \"\"\"\n",
    "    \n",
    "    # quering if the graph is directed\n",
    "    Directed = directed(dict_graph)\n",
    "    \n",
    "    # using a variable to print the output\n",
    "    if Directed: \n",
    "        IsDirectedPrint = 'directed'\n",
    "    else:\n",
    "        IsDirectedPrint = 'undirected'\n",
    "        \n",
    "    # computing the number of users\n",
    "    NofUsers = n_users(dict_graph) \n",
    "    \n",
    "    # computing the number of interactions\n",
    "    NofInteractions = n_interactions(dict_graph)\n",
    "    \n",
    "    # computing the avarege number of links per user\n",
    "    AvgUserLinks = average_n_links(dict_graph)\n",
    "    \n",
    "    # computing density degree\n",
    "    DensityDegree = 2 * NofInteractions / NofUsers**2\n",
    "    \n",
    "    # evaluating sparsity/density\n",
    "    if NofUsers / NofInteractions**2 < 10:\n",
    "        SparseDense = 'sparse'\n",
    "    else:\n",
    "        SparseDense = 'dense'\n",
    "        \n",
    "    # print the results\n",
    "    print(f\"The input graph is -> {IsDirectedPrint}\")\n",
    "    print(f\"Number of users -> {NofUsers}\")\n",
    "    print(f\"Number of answers/comments -> {NofInteractions}\")\n",
    "    print(f\"Average number of links per user -> {AvgUserLinks:.2}\")\n",
    "    print(f\"Density degree -> {DensityDegree: .2}\")\n",
    "    print(f\"The graph is -> {SparseDense}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4fd84ba2-5d0e-4890-a02a-5d8fa389a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input graph is -> directed\n",
      "Number of users -> 1044\n",
      "Number of answers/comments -> 1542\n",
      "Average number of links per user -> 1.5\n",
      "Density degree ->  0.0028\n",
      "The graph is -> sparse\n"
     ]
    }
   ],
   "source": [
    "F1_OverallFeatures(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c082fc5-e279-4ed4-aa69-ef9435efe06e",
   "metadata": {},
   "source": [
    "### Functionality 2 - Find the best users!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114fc890-f318-422f-9cd0-7d649dd46a6e",
   "metadata": {},
   "source": [
    "#### Degree centrality\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the normalized degree centrality of node $v$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d_v}{|V|-1} \\approx \\frac{d_v}{|V|}\n",
    "\\end{equation}\n",
    "\n",
    "with $d_v$ the degree of the node $v$, i.e. the number of edges incident to the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32c83582-ab3e-47e1-864f-124be4f1bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the degree as \"out-degree\"\n",
    "def degree(dict_graph, node):\n",
    "    return len(list(dict_graph[node].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83655f9a-1eea-4b88-96e6-802b18206f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the definition\n",
    "def degree_centrality(dict_graph, node):\n",
    "    out = degree(dict_graph, node) / n_interactions(dict_graph)\n",
    "    print(f\"{out:.2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b48406a-a9ec-4841-971a-5cd472374042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0013\n"
     ]
    }
   ],
   "source": [
    "degree_centrality(d1, \"30155\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e52b09d0-6513-40ae-9d13-0dddf34cc31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0019\n"
     ]
    }
   ],
   "source": [
    "degree_centrality(d1, \"4120\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45da09-30c8-4288-b7d4-0744200af52a",
   "metadata": {},
   "source": [
    "#### Closeness centrality\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the normalized closeness centrality of node $v$ is:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{|V|-1}{\\sum_{u \\epsilon V} d(v,u)} \\approx \\frac{|V|}{\\sum_{u \\epsilon V} d(v,u)}\n",
    "\\end{equation}\n",
    "\n",
    "with $d(v,u)$ the distance between nodes $v$ and $u$, that is the length of a shortest path between $v$ and $u$.\\\n",
    "As a design choice $d(v,u)$ is taken as the inverse of the weight of the edge of $(v,u)$, this leads to an inverse relationship between interaction and distances: the more a user posts, the closer he gets to the comunity.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df2514-d620-44b1-a5c5-8798eedbc972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a graph as a dict of dicts, the start node\n",
    "# Output: a list of tuples like --> {node_1: dist_1, node_2: dist_2, . . . , node_n: dist_n}\n",
    "\n",
    "def shortest_path_Dijkstra(dict_graph, node):\n",
    "    # Initialize a new dictionary with same keys of the original graph and empty values\n",
    "    nodes = dict.fromkeys(dict_graph.keys())\n",
    "    \n",
    "    # Initialize the algorithm\n",
    "    nodes[node] = 0\n",
    "    \n",
    "    # Start calculate distances\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2e433537-64c2-4ca1-b45b-38a157bdea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_closeness_centrality(dict_graph, v):\n",
    "    \n",
    "    # Create a list with all the nodes except the one considered\n",
    "    nodes = dict_graph.keys().remove(node)\n",
    "    \n",
    "    # Iterate and calculate the denominator\n",
    "    denom = 0\n",
    "    for u in nodes:\n",
    "        denom += shortest_path_Dijkstra(dict_graph, v)\n",
    "        \n",
    "    # Return the result\n",
    "    return (n_users(dict_graph) - 1) / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df06f29-b1a6-496e-8dbb-6d1149e30120",
   "metadata": {},
   "source": [
    "#### Page rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "70004ef9-ef61-4945-9718-9a8c2071aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PageRank(Graph, Node):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464eae7-5352-4065-841f-c29e847a46b5",
   "metadata": {},
   "source": [
    "#### Betweeness\n",
    "\n",
    "As defined in *Introduction to Graph Concepts for Data Science of Aris Anagnostopoulos*, the Betweeness centrality of node $v$ is:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{u, w \\epsilon V \\backslash \\{v\\}} \\frac{g_{u w}^v}{g_{uw}} \\frac{2}{|V|^2 - 3|V| + 2} \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "with $g_{uw}$ the shortest path that connects nodes $u$ and $w$ and $g_{u w}^v$ the set of those shortest paths between u and w that contain node $v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e51e9c76-1dc1-462d-aa22-2f503cd3c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Betweeness(Graph, Node):\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "302fb6e4-12fb-4304-b97c-c6dac18fa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F2_BestUser(Node, TimeInterval, Metric, Graph = MergedGraphs):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    A user/node\n",
    "    A tuple of two dates in ISO format representing an interval of time, e.g. (2015-12-04, 2016-12-04) \n",
    "    An integer corresponding to the following metrics: \n",
    "      1 -> Betweeness \n",
    "      2 -> PageRank\n",
    "      3 -> ClosenessCentrality \n",
    "      4 -> DegreeCentrality\n",
    "    The graph on which to perform the analysis.\n",
    "\n",
    "    Output:\n",
    "    The value of the given metric applied over the complete graph for the given interval of time.\n",
    "    \"\"\"\n",
    "\n",
    "    TimeInterval = tuple(map(dt.fromisoformat, TimeInterval)) # converting time interval into datetime format\n",
    "    IntToMetric = {1: Betweeness, 2: PageRank, 3: ClosenessCentrality, 4: DegreeCentrality} # dictionary associating the\n",
    "                                                                                           # input integer to the\n",
    "                                                                                           # corresponding metric function\n",
    "\n",
    "    TimeIntervalGraph = Graph.copy() # creating a copy on which to perform the time filtering\n",
    "    TimeIntervalGraph.remove_edges_from([(n1, n2) for n1, n2, time in TimeIntervalGraph.edges(data=\"time\") \n",
    "                                        if (time >= TimeInterval[0] & time <= TimeInterval[1])]) # removing the edges that not belong\n",
    "                                                                                                 # to the input time interval  \n",
    "\n",
    "    return IntToMetric[Metric](TimeIntervalGraph, Node)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
